# ==============================================
# KGRAG Configuration Template
# ==============================================
# Copy this file to .env and configure your settings

# ==============================================
# API Configuration
# ==============================================
OPENAI_API_KEY=your_openai_api_key_here

# ==============================================
# Model Configuration
# ==============================================
# Primary models used throughout the system
DEFAULT_MODEL=gpt-4o-mini
EMBED_MODEL=text-embedding-3-small
CHAT_MODEL=gpt-4o-mini

# Model parameters
TEMPERATURE=0.5
MAX_TOKENS_RESPONSE=2000

# ==============================================
# Text Processing Configuration
# ==============================================
# Chunking parameters for document processing
MAX_TOKENS=3000
OVERLAP=300
MAX_WORKERS=10

# Alternative chunking settings (used in build_graph.py)
ALT_MAX_TOKENS=1200
ALT_OVERLAP=100

# ==============================================
# Topic and Subtopic Selection
# ==============================================
# Topic selection range
TOPIC_CHOICE_MIN=5
TOPIC_CHOICE_MAX=10

# Subtopic selection range  
SUBTOPIC_CHOICE_MIN=10
SUBTOPIC_CHOICE_MAX=25

# Retry configuration
MAX_RETRIES=10
RETRY_BACKOFF=0.2

# ==============================================
# RAG Retrieval Parameters
# ==============================================
# K1: First-stage retrieval (edge search)
TOP_K1=50

# K2: Second-stage retrieval (chunk selection)
TOP_K2=10

# Alternative settings for long documents
TOP_K1_LONG=25
TOP_K2_LONG=5

# Embedding search parameters
EMBEDDING_TOP_K=5
OVERRETRIEVE_FACTOR=5

# ==============================================
# Generation Parameters
# ==============================================
# Answer generation settings
ANSWER_TEMPERATURE=0.3
ANSWER_MAX_TOKENS=1000

# Context window limits
MAX_CONTEXT_LENGTH=4000

# ==============================================
# Evaluation Configuration
# ==============================================
# Evaluation model (can be different from generation model)
EVAL_MODEL=gpt-4o-mini
EVAL_TEMPERATURE=0.1

# ==============================================
# System Configuration
# ==============================================
# Logging
LOG_LEVEL=INFO
LOG_FILE=kgrag.log

# Performance
BATCH_SIZE=32
TIMEOUT_SECONDS=30

# Cache settings
ENABLE_CACHE=true
CACHE_TTL=3600

# ==============================================
# Data Paths (Optional - uses defaults if not set)
# ==============================================
# DATA_DIR=./data
# OUTPUT_DIR=./output
# CACHE_DIR=./cache
